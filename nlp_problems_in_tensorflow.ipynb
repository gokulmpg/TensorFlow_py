{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBIR6tTI9QcR"
   },
   "source": [
    "Unzipping `nlp_getting_started.zip` gives the following 3 `.csv` files:\n",
    " `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
    " `train.csv` - training samples of real and not real diaster Tweets.\n",
    " `test.csv` - testing samples of real and not real diaster Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HpxZKYdD6V-"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qRvkeYEJIKsw",
    "outputId": "28e2fd66-1a50-4685-94b0-1f57bf7e5968"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn .csv files into pandas DataFrame's\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xGqlnQaLmaT"
   },
   "source": [
    "The training data we downloaded is probably shuffled already. But just to be sure, let's shuffle it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ACCE7h6OMVjR",
    "outputId": "ce040217-1a4b-4199-e446-f4b87988d90d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tDh5t7thI5BM",
    "outputId": "4b7504c3-926c-47fe-94d7-ef4adbda02fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The test data doesn't have a target (that's what we'd try to predict)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4JhBRn5Mn-V"
   },
   "source": [
    "Let's check how many examples of each target we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4P5DnLhIciD",
    "outputId": "375216c9-317b-46a3-be61-b2501ea76e48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQxg7EKKIy5L",
    "outputId": "251920ac-0570-4903-fd55-febbe3c4f987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 7613\n",
      "Total test samples: 3263\n",
      "Total samples: 10876\n"
     ]
    }
   ],
   "source": [
    "# How many samples total?\n",
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vH3EXknTI3bQ",
    "outputId": "f2c69a8e-3a9e-46d7-b05e-aef832742b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@brookesddl I am traumatised the lil shit nearly hopped in the bloody shower with me\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Aircraft debris found on island is from MH370 Malaysia confirms http://t.co/X3RccHKagO\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "This is one violent and belligerent storm. I'm enjoying watching it unfold\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Metal Cutting Sparks Brush Fire In Brighton: A brush fire that was sparked by a landowner cutting metal burned 10Û_ http://t.co/rj7m42AtWS\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "I got evacuated from the cinema 30 mins through Inside Out\n",
      "Kill me please\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "  _, text, target = row\n",
    "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7OJf31TQ-X8s"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWGOTjanBaTQ",
    "outputId": "01e3d66e-8c1e-458d-9c65-9c445063a488"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqhvQK9wBTbw",
    "outputId": "dfb2b4ae-e808-421a-eed3-531c39fcad24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 training sentences and their labels\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PVcZk-LcNunF"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextVectorization \u001b[38;5;66;03m# after TensorFlow 2.6\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Before TensorFlow 2.6\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Use the default TextVectorization variables\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization # after TensorFlow 2.6\n",
    "\n",
    "# Before TensorFlow 2.6\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization \n",
    "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
    "# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n",
    "\n",
    "# Use the default TextVectorization variables\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
    "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQ3ZCINnR56H",
    "outputId": "8c643c75-12d9-4329-8d14-ffdff2e32ecc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average number of tokens (words) in training Tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFGTRcw8Hv7R"
   },
   "source": [
    "Now let's create another `TextVectorization` object using our custom parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eYPcGwdbafmW"
   },
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSWycfB3H3wV"
   },
   "source": [
    "Beautiful!\n",
    "\n",
    "To map our `TextVectorization` instance `text_vectorizer` to our data, we can call the `adapt()` method on it whilst passing it our training text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0083KHXPO4m2"
   },
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Syh0VB9wIHUq"
   },
   "source": [
    "Training data mapped! Let's try our `text_vectorizer` on a custom sentence (one similar to what you might see in the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uizmdJKvO2OW",
    "outputId": "98a93609-ff3c-4ca7-bc3f-1fba622c66d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZFka4BtRR6_",
    "outputId": "63d5a3b0-7e9f-4660-f1a4-1c07043cd3dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "new summer long thin body bag hip A word skirt Blue http://t.co/lvKoEMsq8m http://t.co/CjiRhHh4vj      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[  50,  270,  480, 3335,   83,  322, 2436,    3, 1448, 3407,  824,\n",
       "           1,    1,    0,    0]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nwNdgAZIhna",
    "outputId": "a9e03ebb-4a87-4bef-d224-c0dcaed96181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
    "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") \n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsB4StymSk_s",
    "outputId": "ae557704-a630-41ce-b0e7-ba6558165aff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x7f0c118dcc40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfML_IzlSUho"
   },
   "source": [
    "Excellent, notice how `embedding` is a TensoFlow layer? This is important because we can use it as part of a model, meaning its parameters (word representations) can be updated and improved as the model learns.\n",
    "\n",
    "How about we try it out on a sample sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Re6Eew6SZnG",
    "outputId": "e7f62bb5-49d0-4f77-8c2c-bff0c941ba94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Now on #ComDev #Asia: Radio stations in #Bangladesh broadcasting #programs ?to address the upcoming cyclone #komen http://t.co/iOVr4yMLKp      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.04868475, -0.03902867, -0.01375594, ...,  0.01682534,\n",
       "         -0.0439401 , -0.04604518],\n",
       "        [-0.04827927, -0.00328457,  0.02171678, ..., -0.03261749,\n",
       "         -0.01061803, -0.0481179 ],\n",
       "        [-0.02431345,  0.01104342,  0.00933889, ..., -0.04607272,\n",
       "         -0.00651377,  0.03853123],\n",
       "        ...,\n",
       "        [-0.03270339,  0.03608486,  0.03573406, ...,  0.03622421,\n",
       "          0.03427652, -0.03483479],\n",
       "        [-0.0489977 ,  0.01962234,  0.02186165, ...,  0.03139002,\n",
       "         -0.00744159,  0.0428594 ],\n",
       "        [ 0.01265842,  0.02462569, -0.04731182, ...,  0.00403734,\n",
       "          0.0431679 ,  0.03959754]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4Sn8o9pTBE5"
   },
   "source": [
    "Each token in the sentence gets turned into a length 128 feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_VBepuSTBDW",
    "outputId": "f04fe6bf-bcac-4dd2-eff7-e9ed370e26c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([-0.04868475, -0.03902867, -0.01375594,  0.01587117, -0.02964617,\n",
       "        0.00738639, -0.03109504,  0.03008839, -0.01458266, -0.03069887,\n",
       "       -0.04926676, -0.03454053, -0.04019499, -0.04406711,  0.01975099,\n",
       "        0.02852687, -0.04052209, -0.03800124,  0.03438697, -0.0118026 ,\n",
       "       -0.03470664, -0.01146972,  0.0449667 , -0.00269016,  0.02131964,\n",
       "       -0.04141569, -0.03724197,  0.01624352,  0.03269556,  0.03813741,\n",
       "        0.03606123,  0.00698509, -0.03569689,  0.02056131, -0.03467314,\n",
       "        0.01110398,  0.02095172,  0.02219674, -0.04576088, -0.04229112,\n",
       "       -0.02345047,  0.02578488,  0.02985479, -0.00203061,  0.03920727,\n",
       "        0.04065951,  0.03973453,  0.03947322,  0.01699554,  0.0021927 ,\n",
       "        0.03676197, -0.04327145,  0.02495482,  0.02447238, -0.04413594,\n",
       "       -0.01388069, -0.00375951, -0.0328602 , -0.00067427,  0.01808068,\n",
       "        0.04227355,  0.02817165,  0.01965401, -0.01514393,  0.01905935,\n",
       "       -0.03820103, -0.04916845,  0.02303007,  0.00830983,  0.01011454,\n",
       "       -0.04043181,  0.02080727, -0.03319015,  0.04188809, -0.01183917,\n",
       "       -0.01822531, -0.02172413,  0.03059311,  0.02727925, -0.00328885,\n",
       "       -0.00808424, -0.02095444, -0.00894216,  0.00770078, -0.00439024,\n",
       "        0.03637768,  0.02007255, -0.02650907, -0.01374531,  0.01806785,\n",
       "       -0.03309877, -0.01076321, -0.04107616,  0.01709371,  0.04567242,\n",
       "       -0.01824218,  0.02805582,  0.02974418, -0.04001283, -0.04077357,\n",
       "        0.00323737,  0.04038842, -0.00992844, -0.03974843,  0.04533138,\n",
       "        0.04738795,  0.02837384,  0.03874009, -0.01673441, -0.00258055,\n",
       "       -0.01975214, -0.04166807, -0.02483889, -0.02804886,  0.04608755,\n",
       "        0.03544754,  0.02697959,  0.00242041,  0.00101637, -0.01162767,\n",
       "       -0.00497937,  0.00540714, -0.01258825,  0.00779672,  0.02742722,\n",
       "        0.01682534, -0.0439401 , -0.04604518], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "xFqjqWcXtOOs",
    "outputId": "9f5e6d10-7fe1-441b-fac9-c3e0a45e6a3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soPfnpmQuUIP",
    "outputId": "402cf204-0d0f-4cd0-d647-b2e3e260c72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUv5dyuibf3M"
   },
   "source": [
    "How about we make some predictions with our baseline model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7n89JxrJufcf",
    "outputId": "7f0222e7-6229-442e-8615-7cc4ac483e6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gLmNlDjIxGgJ"
   },
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sgy1omMhwr52",
    "outputId": "15bd29d7-97ca-46f4-9edc-ad8d8d7f543e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "PVMPUd3HTit5"
   },
   "outputs": [],
   "source": [
    "# Create tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pib8hHtu7vt1"
   },
   "source": [
    "Now we've got a TensorBoard callback function ready to go, let's build our first deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "a_rVtJA7yVBI"
   },
   "outputs": [],
   "source": [
    "# Build model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x) # create an embedding of the numerized numbers\n",
    "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Ubq0ctLD8CQq"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crgltz1O9uku"
   },
   "source": [
    "Model compiled. Let's get a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1YRYpJIfTvHV",
    "outputId": "1f3854ae-056b-4bd0-8894-e8d9ec3df3cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/simple_dense_model/20230526-001451\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 18s 55ms/step - loss: 0.6098 - accuracy: 0.6936 - val_loss: 0.5360 - val_accuracy: 0.7559\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.4417 - accuracy: 0.8194 - val_loss: 0.4691 - val_accuracy: 0.7887\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.3471 - accuracy: 0.8616 - val_loss: 0.4588 - val_accuracy: 0.7887\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.2856 - accuracy: 0.8921 - val_loss: 0.4637 - val_accuracy: 0.7913\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2388 - accuracy: 0.9115 - val_loss: 0.4760 - val_accuracy: 0.7861\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
    "                                                                     experiment_name=\"simple_dense_model\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZR5_j9C_LW-"
   },
   "source": [
    "Nice! Since we're using such a simple model, each epoch processes very quickly.\n",
    "\n",
    "Let's check our model's performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSTS87YGzuBG",
    "outputId": "416c8d9a-5f01-4c3c-e8e1-a0ceb57d97a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4760194718837738, 0.7860892415046692]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5M2CTAetBVfW",
    "outputId": "e539ac4f-33ed-40be-9921-30378ad8b3c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
       " array([[-0.01078545,  0.05590528,  0.03125916, ..., -0.0312557 ,\n",
       "         -0.05340781, -0.03800201],\n",
       "        [-0.02370532,  0.01161508,  0.0097667 , ..., -0.04962142,\n",
       "         -0.00636482,  0.03781125],\n",
       "        [-0.05472897,  0.05356752,  0.02146765, ...,  0.05501205,\n",
       "          0.01705659, -0.05321405],\n",
       "        ...,\n",
       "        [ 0.01756669, -0.03676652, -0.00949616, ..., -0.00987446,\n",
       "         -0.04183743,  0.03016822],\n",
       "        [-0.07823883,  0.06081628, -0.07657789, ...,  0.07998865,\n",
       "         -0.05281445, -0.02332675],\n",
       "        [-0.03393482,  0.08871375, -0.06819566, ...,  0.06992952,\n",
       "         -0.09992232, -0.02705033]], dtype=float32)>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3rfhJFSBrga",
    "outputId": "442907dd-0889-421f-8846-b312c107b53f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "t6UrSgRVU6pl"
   },
   "outputs": [],
   "source": [
    "# # View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
    "# # Upload TensorBoard dev records\n",
    "# !tensorboard dev upload --logdir ./model_logs \\\n",
    "#   --name \"First deep model on text data\" \\\n",
    "#   --description \"Trying a dense model with an embedding layer\" \\\n",
    "#   --one_shot # exits the uploader when upload has finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "DVyJl-VE1ACz"
   },
   "outputs": [],
   "source": [
    "# If you need to remove previous experiments, you can do so using the following command\n",
    "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5X7kbEmAzzxM",
    "outputId": "7433ca4a-f851-41b6-9d20-2cc45dc08bdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4068562 ],\n",
       "       [0.74714756],\n",
       "       [0.9978309 ],\n",
       "       [0.10913013],\n",
       "       [0.10925023],\n",
       "       [0.93645686],\n",
       "       [0.91428435],\n",
       "       [0.99250424],\n",
       "       [0.96829313],\n",
       "       [0.26842445]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (these come back in the form of probabilities)\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWU5e1NLAKJ9"
   },
   "source": [
    "Since our final layer uses a sigmoid activation function, we get our predictions back in the form of probabilities.\n",
    "\n",
    "To convert them to prediction classes, we'll use `tf.round()`, meaning prediction probabilities below 0.5 will be rounded to 0 and those above 0.5 will be rounded to 1.\n",
    "\n",
    "> 🔑 **Note:** In practice, the output threshold of a sigmoid prediction probability doesn't necessarily have to 0.5. For example, through testing, you may find that a cut off of 0.25 is better for your chosen evaluation metrics. A common example of this threshold cutoff is the [precision-recall tradeoff](https://en.wikipedia.org/wiki/Precision_and_recall#Introduction) (search for the keyword \"tradeoff\" to learn about the phenomenon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qf-R_1vsz47P",
    "outputId": "b42abf4f-219b-46a6-ad23-eeb0255b1084"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn prediction probabilities into single-dimension tensor of floats\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zc3ryY0yCHcI"
   },
   "source": [
    "Now we've got our model's predictions in the form of classes, we can use our `calculate_results()` function to compare them to the ground truth validation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDEEhYTF0X1y",
    "outputId": "8c3fa99e-d247-4c31-feb4-60f75968a406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.60892388451444,\n",
       " 'precision': 0.7903277546022673,\n",
       " 'recall': 0.7860892388451444,\n",
       " 'f1': 0.7832971347503846}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 metrics\n",
    "model_1_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnkK6Uc7CYlX"
   },
   "source": [
    "How about we compare our first deep model to our baseline model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jp88ystW1m0d",
    "outputId": "e06d9d8e-ceec-413f-e3a1-6e026150fb8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is our simple Keras model better than our baseline model?\n",
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUINrCdRCpFf"
   },
   "source": [
    "Since we'll be doing this kind of comparison (baseline compared to new model) quite a few times, let's create a function to help us out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wo3norTG3GrE",
    "outputId": "902c6819-c78e-4dba-b1f8-a8cfad0db80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 78.61, Difference: -0.66\n",
      "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
      "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
     ]
    }
   ],
   "source": [
    "# Create a helper function to compare our baseline results to new model results\n",
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
    "                                new_model_results=model_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-DkcfRQBVXuJ",
    "outputId": "444cef16-b633-4e9b-aa68-c9d3929fd02a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary from the text vectorization layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzmAPJXQEx6r"
   },
   "source": [
    "And now let's get our embedding layer's weights (these are the numerical representations of each word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8EUR9PwrZphh",
    "outputId": "4a0ec496-528b-4f33-eb36-a2f2b69f443a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xJ5LrInWDLo",
    "outputId": "f315c987-e355-4aac-ea9a-b2230d4f35fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Get the weight matrix of embedding layer \n",
    "# (these are the numerical patterns between the text in the training dataset the model has learned)\n",
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape) # same size as vocab size and embedding_dim (each word is a embedding_dim size vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzOJhJHPW1ju"
   },
   "source": [
    "Now we've got these two objects, we can use the [Embedding Projector tool](http://projector.tensorflow.org/_) to visualize our embedding. \n",
    "\n",
    "To use the Embedding Projector tool, we need two files:\n",
    "* The embedding vectors (same as embedding weights).\n",
    "* The meta data of the embedding vectors (the words they represent - our vocabulary).\n",
    "\n",
    "Right now, we've got of these files as Python objects. To download them to file, we're going to [use the code example available on the TensorFlow word embeddings tutorial page](https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "4e9rfcK6WxQE"
   },
   "outputs": [],
   "source": [
    "# # Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
    "# import io\n",
    "\n",
    "# # Create output writers\n",
    "# out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
    "# out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "# # Write embedding vectors and words to file\n",
    "# for num, word in enumerate(words_in_vocab):\n",
    "#   if num == 0: \n",
    "#      continue # skip padding token\n",
    "#   vec = embed_weights[num]\n",
    "#   out_m.write(word + \"\\n\") # write words to file\n",
    "#   out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
    "# out_v.close()\n",
    "# out_m.close()\n",
    "\n",
    "# # Download files locally to upload to Embedding Projector\n",
    "# try:\n",
    "#   from google.colab import files\n",
    "# except ImportError:\n",
    "#   pass\n",
    "# else:\n",
    "#   files.download(\"embedding_vectors.tsv\")\n",
    "#   files.download(\"embedding_metadata.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pi3vjpFU46hi",
    "outputId": "f677d33f-a235-4a72-b2f9-315cb845f3dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_2\")\n",
    "\n",
    "\n",
    "# Create LSTM model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_2_embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
    "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1wfTARuwWDg"
   },
   "source": [
    "> 🔑 **Note:** Reading the documentation for the [TensorFlow LSTM layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM), you'll find a plethora of parameters. Many of these have been tuned to make sure they compute as fast as possible. The main ones you'll be looking to adjust are `units` (number of hidden units) and `return_sequences` (set this to `True` when stacking LSTM or other recurrent layers).\n",
    "\n",
    "Now we've got our LSTM model built, let's compile it using `\"binary_crossentropy\"` loss and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "pWdt3bFRwG6w"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2e_t8RFxgXG"
   },
   "source": [
    "And before we fit our model to the data, let's get a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IAjdfDfLwK_R",
    "outputId": "f150e74a-26f2-40bc-d5c1-083bc82e4ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YgZ7ojDvwKcq",
    "outputId": "d25ace18-6b55-43ee-f1d5-fb6b3bea620c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/LSTM/20230526-001518\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 13s 44ms/step - loss: 0.5074 - accuracy: 0.7460 - val_loss: 0.4590 - val_accuracy: 0.7743\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.3168 - accuracy: 0.8716 - val_loss: 0.5119 - val_accuracy: 0.7756\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.2198 - accuracy: 0.9155 - val_loss: 0.5876 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1577 - accuracy: 0.9442 - val_loss: 0.5923 - val_accuracy: 0.7795\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1108 - accuracy: 0.9577 - val_loss: 0.8550 - val_accuracy: 0.7559\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"LSTM\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gikGe_Z16PP"
   },
   "source": [
    "Nice! We've got our first trained RNN model using LSTM cells. Let's make some predictions with it.\n",
    "\n",
    "The same thing will happen as before, due to the sigmoid activiation function in the final layer, when we call the `predict()` method on our model, it'll return prediction probabilities rather than classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c_lVbKLemrU",
    "outputId": "02ef8004-44e7-4e92-e221-6bbd1623a975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.00630066],\n",
       "        [0.7862389 ],\n",
       "        [0.9991792 ],\n",
       "        [0.06841089],\n",
       "        [0.00448257],\n",
       "        [0.99932086],\n",
       "        [0.8617405 ],\n",
       "        [0.99968505],\n",
       "        [0.9993248 ],\n",
       "        [0.57989997]], dtype=float32))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ6ope-ddpOo"
   },
   "source": [
    "We can turn these prediction probabilities into prediction classes by rounding to the nearest integer (by default, prediction probabilities under 0.5 will go to 0 and those over 0.5 will go to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFnIhtyE7hlb",
    "outputId": "b732247d-1378-42a2-ab1a-bf5bc332aeca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTBy4poXd_7p"
   },
   "source": [
    "Beautiful, now let's use our `caculate_results()` function to evaluate our LSTM model and our `compare_baseline_to_new_results()` function to compare it to our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3iHXv04y76vj",
    "outputId": "17b80b37-82bd-40e7-c86b-73dc2eb26e39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.59055118110236,\n",
       " 'precision': 0.7567160722556739,\n",
       " 'recall': 0.7559055118110236,\n",
       " 'f1': 0.7539595513230887}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate LSTM model results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdQGn2L68B5Q",
    "outputId": "1011e2a5-496f-4a1d-a9d7-d331d047a219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 75.59, Difference: -3.67\n",
      "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
      "Baseline recall: 0.79, New recall: 0.76, Difference: -0.04\n",
      "Baseline f1: 0.79, New f1: 0.75, Difference: -0.03\n"
     ]
    }
   ],
   "source": [
    "# Compare model 2 to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "SoSCGq3H47Yo"
   },
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_3\")\n",
    "\n",
    "# Build an RNN using the GRU cell\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_3_embedding(x)\n",
    "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
    "x = layers.GRU(64)(x) \n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLT5maFWhKH1"
   },
   "source": [
    "TensorFlow makes it easy to use powerful components such as the GRU cell in our models. And now our third model is built, let's compile it, just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "lBL1mb31hHDS"
   },
   "outputs": [],
   "source": [
    "# Compile GRU model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvnksvkmha2A"
   },
   "source": [
    "What does a summary of our model look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVnB5yQeiAWs",
    "outputId": "a730270e-0857-4fbb-a74c-3471f8d26639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of the GRU model\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcXzKqgXhdez"
   },
   "source": [
    "Notice the difference in number of trainable parameters between `model_2` (LSTM) and `model_3` (GRU). The difference comes from the LSTM cell having more trainable parameters than the GRU cell.\n",
    "\n",
    "We'll fit our model just as we've been doing previously. We'll also track our models results using our `create_tensorboard_callback()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gvamg5JOh_jC",
    "outputId": "cfb59be7-625b-4f75-abb6-6db6c9b003ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/GRU/20230526-001539\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 11s 43ms/step - loss: 0.5274 - accuracy: 0.7231 - val_loss: 0.4539 - val_accuracy: 0.7795\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.3179 - accuracy: 0.8686 - val_loss: 0.4850 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.2149 - accuracy: 0.9187 - val_loss: 0.5544 - val_accuracy: 0.7717\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1517 - accuracy: 0.9488 - val_loss: 0.6279 - val_accuracy: 0.7835\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1145 - accuracy: 0.9609 - val_loss: 0.6063 - val_accuracy: 0.7756\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hM4mQj1Sh7Gn"
   },
   "source": [
    "Due to the optimized default settings of the GRU cell in TensorFlow, training doesn't take long at all. \n",
    "\n",
    "Time to make some predictions on the validation samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5TUVHCl9pe-",
    "outputId": "da5a388d-37ac-41fc-a0de-bc5d50f5abea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.31703022],\n",
       "        [0.9160779 ],\n",
       "        [0.9977792 ],\n",
       "        [0.14830083],\n",
       "        [0.01086212],\n",
       "        [0.9908326 ],\n",
       "        [0.6938264 ],\n",
       "        [0.9978917 ],\n",
       "        [0.99662066],\n",
       "        [0.4299642 ]], dtype=float32))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation data\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs.shape, model_3_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hasS7dzRiYQh"
   },
   "source": [
    "Again we get an array of prediction probabilities back which we can convert to prediction classes by rounding them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "haILbddg98CY",
    "outputId": "d7a9ee73-a219-4288-9ef4-46d999cc4e25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to prediction classes\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7yAgh-viglB"
   },
   "source": [
    "Now we've got predicted classes, let's evaluate them against the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9OZbQu1-LPp",
    "outputId": "b64a3f45-10c5-416e-d362-33d994fe35ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.55905511811024,\n",
       " 'precision': 0.776326889347514,\n",
       " 'recall': 0.7755905511811023,\n",
       " 'f1': 0.7740902496040959}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuate model_3 results\n",
    "model_3_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9t7wcALiuRk"
   },
   "source": [
    "Finally we can compare our GRU model's results to our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7AE6vtn-RQZ",
    "outputId": "c39a27c9-e6a9-40a6-f3b7-05d6ffd20066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.56, Difference: -1.71\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
      "Baseline recall: 0.79, New recall: 0.78, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.01\n"
     ]
    }
   ],
   "source": [
    "# Compare to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_3_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "NAU9dvGm47_2"
   },
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_4\")\n",
    "\n",
    "# Build a Bidirectional RNN in TensorFlow\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Hm5cwmNm-g4"
   },
   "source": [
    "> 🔑 **Note:** You can use the `Bidirectional` wrapper on any RNN cell in TensorFlow. For example, `layers.Bidirectional(layers.GRU(64))` creates a bidirectional GRU cell.\n",
    "\n",
    "Our bidirectional model is built, let's compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "wP1jeF0am9x0"
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtpYyjsbnEwN"
   },
   "source": [
    "And of course, we'll check out a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sUd9AQ6nFXI",
    "outputId": "05cce0cd-22dc-4181-83dd-5e384cbd44aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of our bidirectional model\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvItfzeZnIE-"
   },
   "source": [
    "Notice the increased number of trainable parameters in `model_4` (bidirectional LSTM) compared to `model_2` (regular LSTM). This is due to the bidirectionality we added to our RNN.\n",
    "\n",
    "Time to fit our bidirectional model and track its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAKY_QbHXPHB",
    "outputId": "93ac80ba-901d-4cc4-8b87-9ad052405efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20230526-001559\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 14s 47ms/step - loss: 0.5096 - accuracy: 0.7447 - val_loss: 0.4585 - val_accuracy: 0.7861\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 0.3140 - accuracy: 0.8726 - val_loss: 0.5086 - val_accuracy: 0.7743\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.2139 - accuracy: 0.9183 - val_loss: 0.5716 - val_accuracy: 0.7730\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1486 - accuracy: 0.9504 - val_loss: 0.6707 - val_accuracy: 0.7703\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.1058 - accuracy: 0.9648 - val_loss: 0.6658 - val_accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (takes longer because of the bidirectional layers)\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkt8GVRHoJz6"
   },
   "source": [
    "Due to the bidirectionality of our model we see a slight increase in training time.\n",
    "\n",
    "Not to worry, it's not too dramatic of an increase.\n",
    "\n",
    "Let's make some predictions with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFc7QHRtXmn7",
    "outputId": "784c4a65-1786-47b9-eb7b-53b920e6d693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05258294],\n",
       "       [0.8495521 ],\n",
       "       [0.99898857],\n",
       "       [0.15441437],\n",
       "       [0.00566462],\n",
       "       [0.99576193],\n",
       "       [0.952807  ],\n",
       "       [0.9993511 ],\n",
       "       [0.99936384],\n",
       "       [0.19425693]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with bidirectional RNN on the validation data\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_9HmNIYobDB"
   },
   "source": [
    "And we'll convert them to prediction classes and evaluate them against the ground truth labels and baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5z8bMdaXw51",
    "outputId": "283d42c0-5e36-4db4-83f2-90fe0c03ff00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-a7Ym_vKYAO4",
    "outputId": "12741d8d-6f89-4481-d4e3-7c5bcd009e09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.77165354330708,\n",
       " 'precision': 0.7675450859410361,\n",
       " 'recall': 0.7677165354330708,\n",
       " 'f1': 0.7667932666650168}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate bidirectional RNN model results\n",
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAET-LKpYT18",
    "outputId": "7cc1d033-17de-40a8-cde4-4d347c718ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.77, Difference: -2.49\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Check to see how the bidirectional model performs against the baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "563hl7nPWP_3",
    "outputId": "b62f7679-d040-48f3-b5b8-414d2d7a3555"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out the embedding, 1D convolutional and max pooling\n",
    "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
    "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over target sequence 5 words at a time\n",
    "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
    "max_pool = layers.GlobalMaxPool1D() \n",
    "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRcxYgs-dxM8",
    "outputId": "26c972c3-8469-47b9-9c7e-8e8fa85ccd4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       " array([[[ 0.01675646, -0.03352517,  0.04817378, ..., -0.02946043,\n",
       "          -0.03770737,  0.01220698],\n",
       "         [-0.00607298,  0.06020833, -0.05641982, ...,  0.08325578,\n",
       "          -0.01878556, -0.08398241],\n",
       "         [-0.0362346 ,  0.00904451, -0.03833614, ...,  0.0051756 ,\n",
       "          -0.00220015, -0.0017492 ],\n",
       "         ...,\n",
       "         [-0.01078545,  0.05590528,  0.03125916, ..., -0.0312557 ,\n",
       "          -0.05340781, -0.03800201],\n",
       "         [-0.01078545,  0.05590528,  0.03125916, ..., -0.0312557 ,\n",
       "          -0.05340781, -0.03800201],\n",
       "         [-0.01078545,  0.05590528,  0.03125916, ..., -0.0312557 ,\n",
       "          -0.05340781, -0.03800201]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
       " array([[[0.        , 0.10975833, 0.        , 0.        , 0.        ,\n",
       "          0.06834612, 0.        , 0.02298634, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.06889185,\n",
       "          0.08162662, 0.        , 0.        , 0.03804683, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.00810859, 0.02383356,\n",
       "          0.        , 0.00385817, 0.        , 0.01310921, 0.        ,\n",
       "          0.        , 0.16110645],\n",
       "         [0.05000008, 0.        , 0.03852113, 0.0149918 , 0.03014192,\n",
       "          0.04613257, 0.        , 0.        , 0.        , 0.05233994,\n",
       "          0.        , 0.        , 0.07095916, 0.03590994, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.05599808,\n",
       "          0.04344876, 0.04021783, 0.        , 0.06110618, 0.        ,\n",
       "          0.        , 0.        , 0.00198402, 0.        , 0.03175152,\n",
       "          0.        , 0.04452901],\n",
       "         [0.        , 0.05068349, 0.06747732, 0.        , 0.        ,\n",
       "          0.04893802, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.0853087 , 0.01114925, 0.00223987,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.10797694, 0.02317763,\n",
       "          0.        , 0.01130794, 0.        , 0.01777459, 0.        ,\n",
       "          0.        , 0.02142338],\n",
       "         [0.        , 0.01030538, 0.        , 0.        , 0.02127263,\n",
       "          0.06377578, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.03660904, 0.        , 0.13293687, 0.06086106, 0.        ,\n",
       "          0.        , 0.        , 0.03161986, 0.00114628, 0.02163697,\n",
       "          0.        , 0.        , 0.        , 0.04408561, 0.        ,\n",
       "          0.01193662, 0.        , 0.        , 0.01174912, 0.03890226,\n",
       "          0.        , 0.06139129],\n",
       "         [0.        , 0.        , 0.00959204, 0.        , 0.03472092,\n",
       "          0.03202822, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.00390257, 0.        , 0.07451484, 0.00349154, 0.        ,\n",
       "          0.        , 0.02155435, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.09407972, 0.        ,\n",
       "          0.        , 0.00077316, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.06074456],\n",
       "         [0.        , 0.03225943, 0.01736662, 0.        , 0.01197381,\n",
       "          0.02301392, 0.        , 0.        , 0.        , 0.00205472,\n",
       "          0.02762672, 0.        , 0.06565619, 0.00253076, 0.        ,\n",
       "          0.        , 0.00745697, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.09595221, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.01910873, 0.        ,\n",
       "          0.        , 0.06507206],\n",
       "         [0.        , 0.03225943, 0.01736662, 0.        , 0.01197381,\n",
       "          0.02301392, 0.        , 0.        , 0.        , 0.00205472,\n",
       "          0.02762672, 0.        , 0.06565619, 0.00253076, 0.        ,\n",
       "          0.        , 0.00745697, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.09595221, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.01910873, 0.        ,\n",
       "          0.        , 0.06507206],\n",
       "         [0.        , 0.03225943, 0.01736662, 0.        , 0.01197381,\n",
       "          0.02301392, 0.        , 0.        , 0.        , 0.00205472,\n",
       "          0.02762672, 0.        , 0.06565619, 0.00253076, 0.        ,\n",
       "          0.        , 0.00745697, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.09595221, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.01910873, 0.        ,\n",
       "          0.        , 0.06507206],\n",
       "         [0.        , 0.03225943, 0.01736662, 0.        , 0.01197381,\n",
       "          0.02301392, 0.        , 0.        , 0.        , 0.00205472,\n",
       "          0.02762672, 0.        , 0.06565619, 0.00253076, 0.        ,\n",
       "          0.        , 0.00745697, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.09595221, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.01910873, 0.        ,\n",
       "          0.        , 0.06507206],\n",
       "         [0.        , 0.03225943, 0.01736662, 0.        , 0.01197381,\n",
       "          0.02301392, 0.        , 0.        , 0.        , 0.00205472,\n",
       "          0.02762672, 0.        , 0.06565619, 0.00253076, 0.        ,\n",
       "          0.        , 0.00745697, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.09595221, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.01910873, 0.        ,\n",
       "          0.        , 0.06507206],\n",
       "         [0.        , 0.03225943, 0.01736662, 0.        , 0.01197381,\n",
       "          0.02301392, 0.        , 0.        , 0.        , 0.00205472,\n",
       "          0.02762672, 0.        , 0.06565619, 0.00253076, 0.        ,\n",
       "          0.        , 0.00745697, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.09595221, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.01910873, 0.        ,\n",
       "          0.        , 0.06507206]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       " array([[0.05000008, 0.10975833, 0.06747732, 0.0149918 , 0.03472092,\n",
       "         0.06834612, 0.        , 0.02298634, 0.        , 0.05233994,\n",
       "         0.03660904, 0.        , 0.13293687, 0.06086106, 0.06889185,\n",
       "         0.08162662, 0.02155435, 0.03161986, 0.03804683, 0.05599808,\n",
       "         0.04344876, 0.04021783, 0.        , 0.10797694, 0.02383356,\n",
       "         0.01193662, 0.01130794, 0.00198402, 0.01910873, 0.03890226,\n",
       "         0.        , 0.16110645]], dtype=float32)>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the outputs of each layer\n",
    "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMcrthJwg3B2"
   },
   "source": [
    "Alright, we've seen the outputs of several components of a CNN for sequences, let's put them together and construct a full model, compile it (just as we've done with our other models) and get a summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9aphPWCYkWN",
    "outputId": "ad2da99b-5180-4a1f-edff-040d5570c8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_5\")\n",
    "\n",
    "# Create 1-dimensional convolutional layer to model sequences\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_5_embedding(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
    "\n",
    "# Compile Conv1D model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a summary of our 1D convolution model\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fzlaKm1ZrMX",
    "outputId": "17d9f01d-529a-4281-c548-06d0597d84b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/Conv1D/20230526-001626\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 11s 42ms/step - loss: 0.5693 - accuracy: 0.7108 - val_loss: 0.4736 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.3426 - accuracy: 0.8600 - val_loss: 0.4677 - val_accuracy: 0.7874\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.2130 - accuracy: 0.9202 - val_loss: 0.5374 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.1366 - accuracy: 0.9564 - val_loss: 0.6076 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0958 - accuracy: 0.9667 - val_loss: 0.6706 - val_accuracy: 0.7874\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"Conv1D\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2up-1tLiXKD"
   },
   "source": [
    "Nice! Thanks to GPU acceleration, our 1D convolutional model trains nice and fast. Let's make some predictions with it and evaluate them just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHYw5GkxZ2OK",
    "outputId": "26ab77ba-08af-4941-bbe2-ca1ac1a69f8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7295443 ],\n",
       "       [0.63939744],\n",
       "       [0.9997949 ],\n",
       "       [0.05865377],\n",
       "       [0.0070557 ],\n",
       "       [0.99556965],\n",
       "       [0.90180606],\n",
       "       [0.9973731 ],\n",
       "       [0.99953437],\n",
       "       [0.6327795 ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with model_5\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9YqTtjiaauS",
    "outputId": "8b990978-011f-4dad-fbf7-adef2b1d1573"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_5 prediction probabilities to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wMY3s1Pnaj34",
    "outputId": "9e77d9ac-8a54-476a-9b74-5f648ce57b2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.74015748031496,\n",
       " 'precision': 0.7900609457201325,\n",
       " 'recall': 0.7874015748031497,\n",
       " 'f1': 0.7852275674790494}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_5 evaluation metrics \n",
    "model_5_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRfF4B6_at8k",
    "outputId": "ad244c98-83c1-404b-f4e4-ac625da44ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 78.74, Difference: -0.52\n",
      "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
      "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.79, Difference: -0.00\n"
     ]
    }
   ],
   "source": [
    "# Compare model_5 results to baseline \n",
    "compare_baseline_to_new_results(baseline_results, model_5_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7piW5jtxbUkV",
    "outputId": "b3e97667-6bdf-4f8c-ff4a-fb425df47a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01154496  0.02487099  0.0287963  -0.01272263  0.03969951  0.08829075\n",
      "  0.02682647  0.05582222 -0.01078761 -0.00596655  0.00640638 -0.01816132\n",
      "  0.0002885   0.09106605  0.05874373 -0.03175148  0.01510153 -0.05164852\n",
      "  0.0099434  -0.06867751 -0.04210396  0.0267539   0.03008907  0.00320448\n",
      " -0.00336865 -0.04790529  0.02267517 -0.00984557 -0.04066692 -0.01285528\n",
      " -0.04665243  0.05630673 -0.03952145  0.00521895  0.02495948 -0.07011835\n",
      "  0.02873133  0.04945794 -0.00634555 -0.08959357  0.02807156 -0.00809173\n",
      " -0.01363956  0.05998395 -0.1036155  -0.05192674  0.00232459 -0.02326531\n",
      " -0.03752431  0.0333298 ], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
    "embed_samples = embed([sample_sentence,\n",
    "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
    "\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvArnKkGb4vu",
    "outputId": "7bf45cb9-58c3-4cf7-8c72-ebbb7043f2f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each sentence has been encoded into a 512 dimension vector\n",
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "ZcbBj0aXqrs9"
   },
   "outputs": [],
   "source": [
    "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[], # shape of inputs coming to our model \n",
    "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
    "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
    "                                        name=\"USE\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvjQl4p7BO_A"
   },
   "source": [
    "Beautiful! Now we've got the USE as a Keras layer, we can use it in a Keras Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_pjIvPuYltA",
    "outputId": "31921c4a-e1c9-4e92-8b41-39b8059f05fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model using the Sequential API\n",
    "model_6 = tf.keras.Sequential([\n",
    "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yukgxOgCCR2Z"
   },
   "source": [
    "Notice the number of paramters in the USE layer, these are the pretrained weights its learned on various text sources (Wikipedia, web news, web question-answer forums, etc, see the [Universal Sentence Encoder paper](https://www.aclweb.org/anthology/D18-2029.pdf) for more).\n",
    "\n",
    "The trainable parameters are only in our output layers, in other words, we're keeping the USE weights frozen and using it as a feature-extractor. We could fine-tune these weights by setting `trainable=True` when creating the `hub.KerasLayer` instance.\n",
    "\n",
    "Now we've got a feature extractor model ready, let's train it and track its results to TensorBoard using our `create_tensorboard_callback()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uX9S0YvafybG",
    "outputId": "4cd696e6-6f3a-4ce7-ca18-f9d5524e682d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20230526-001739\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 11ms/step - loss: 0.5014 - accuracy: 0.7870 - val_loss: 0.4469 - val_accuracy: 0.7992\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.4145 - accuracy: 0.8140 - val_loss: 0.4359 - val_accuracy: 0.8097\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.4000 - accuracy: 0.8216 - val_loss: 0.4319 - val_accuracy: 0.8163\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.3927 - accuracy: 0.8262 - val_loss: 0.4280 - val_accuracy: 0.8176\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.3862 - accuracy: 0.8288 - val_loss: 0.4299 - val_accuracy: 0.8176\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
    "                                                                     \"tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeI0kvVVDmbl"
   },
   "source": [
    "USE model trained! Let's make some predictions with it an evaluate them as we've done with our other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xeyNXqU-gM2p",
    "outputId": "a37fc83d-67f5-4619-e750-1753ac5cf434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.14814094],\n",
       "       [0.74057853],\n",
       "       [0.9886474 ],\n",
       "       [0.22455953],\n",
       "       [0.7404941 ],\n",
       "       [0.6678845 ],\n",
       "       [0.98305696],\n",
       "       [0.9746391 ],\n",
       "       [0.923527  ],\n",
       "       [0.08624077]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gbn1Z0FfgVdx",
    "outputId": "4cc50e0a-f3ec-4931-825b-86731bb0ec21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N2Ow2de3okcb",
    "outputId": "c827c3bf-1c81-4910-894c-35e12e1b93bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.75853018372703,\n",
       " 'precision': 0.8206021490415145,\n",
       " 'recall': 0.8175853018372703,\n",
       " 'f1': 0.8158792847350168}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BHnRHHHgp1r",
    "outputId": "0fe8251d-bad2-43bc-cb2a-aa43c2168d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 81.76, Difference: 2.49\n",
      "Baseline precision: 0.81, New precision: 0.82, Difference: 0.01\n",
      "Baseline recall: 0.79, New recall: 0.82, Difference: 0.02\n",
      "Baseline f1: 0.79, New f1: 0.82, Difference: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Compare TF Hub model to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_6_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "W5Sal8DpjzWm"
   },
   "outputs": [],
   "source": [
    "### NOTE: Making splits like this will lead to data leakage ###\n",
    "### (some of the training examples in the validation set) ###\n",
    "\n",
    "### WRONG WAY TO MAKE SPLITS (train_df_shuffled has already been split) ### \n",
    "\n",
    "# # Create subsets of 10% of the training data\n",
    "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
    "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
    "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
    "# len(train_sentences_10_percent), len(train_labels_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "XHgowC3GUPJH"
   },
   "outputs": [],
   "source": [
    "# One kind of correct way (there are more) to make data subset\n",
    "# (split the already split train_sentences/train_labels)\n",
    "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
    "                                                                                                                            train_labels,\n",
    "                                                                                                                            test_size=0.1,\n",
    "                                                                                                                            random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8jaydmiVnJP",
    "outputId": "62c3c080-1049-44af-98ee-bbe903de7971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 6851\n",
      "Length of 10% training examples: 686\n"
     ]
    }
   ],
   "source": [
    "# Check length of 10 percent datasets\n",
    "print(f\"Total training examples: {len(train_sentences)}\")\n",
    "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E2jr7rSEYT8"
   },
   "source": [
    "Because we've selected a random subset of the training samples, the classes should be roughly balanced (as they are in the full training dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0lEpFT0k0RB",
    "outputId": "7dcda766-f4ed-4f48-fad2-561c19a11b3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    415\n",
       "1    271\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of targets in our subset of data \n",
    "# (this should be close to the distribution of labels in the original train_labels)\n",
    "pd.Series(train_labels_10_percent).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGmxeAOBjdg2",
    "outputId": "b0979399-6bfe-43ae-e75c-7708bd730083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Clone model_6 but reset weights\n",
    "model_7 = tf.keras.models.clone_model(model_6)\n",
    "\n",
    "# Compile model\n",
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a summary (will be same as model_6)\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxFkEM_aFoLK"
   },
   "source": [
    "Notice the layout of `model_7` is the same as `model_6`. Now let's train the newly created model on our 10% training data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LklU2maOkgUF",
    "outputId": "4b930b47-6c6f-48fc-99af-babc7a5eec2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20230526-001758\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 41ms/step - loss: 0.6671 - accuracy: 0.6997 - val_loss: 0.6443 - val_accuracy: 0.7415\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.5895 - accuracy: 0.8309 - val_loss: 0.5846 - val_accuracy: 0.7467\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.5116 - accuracy: 0.8382 - val_loss: 0.5336 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4492 - accuracy: 0.8411 - val_loss: 0.5040 - val_accuracy: 0.7703\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4080 - accuracy: 0.8469 - val_loss: 0.4880 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to 10% of the training data\n",
    "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
    "                              y=train_labels_10_percent,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Qpyqdh-F6Eh"
   },
   "source": [
    "Due to the smaller amount of training data, training happens even quicker than before.\n",
    "\n",
    "Let's evaluate our model's performance after learning on 10% of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ot6MRnznlgCL",
    "outputId": "0ad5f3fd-ee51-47ab-e338-6091e9a1fab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.24178001],\n",
       "       [0.8116845 ],\n",
       "       [0.91511923],\n",
       "       [0.32094172],\n",
       "       [0.587357  ],\n",
       "       [0.82938445],\n",
       "       [0.8401675 ],\n",
       "       [0.8496708 ],\n",
       "       [0.8371127 ],\n",
       "       [0.14010696]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the model trained on 10% of the data\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vj_4aZellpRu",
    "outputId": "996222f8-c15f-4468-fbf2-95b5cbdc5d38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_lTXrDblyva",
    "outputId": "85896126-668c-4197-d4d2-6375b6b9dfb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 0.7760118694840564,\n",
       " 'recall': 0.7703412073490814,\n",
       " 'f1': 0.7665375100103654}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model results\n",
    "model_7_results = calculate_results(val_labels, model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G84ezltll6DT",
    "outputId": "dd9871c4-16fc-4281-91fc-70504128e8f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.03, Difference: -2.23\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_7_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Ex0NSaz7lRf-",
    "outputId": "fb5f5272-6b73-4ee0-e04d-0e01f256ceda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4bf967fe-ed48-4e35-a870-cc6d18c95c35\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>78.608924</td>\n",
       "      <td>0.790328</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.783297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>75.590551</td>\n",
       "      <td>0.756716</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.753960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>77.559055</td>\n",
       "      <td>0.776327</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.774090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>76.771654</td>\n",
       "      <td>0.767545</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.766793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>78.740157</td>\n",
       "      <td>0.790061</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.785228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>81.758530</td>\n",
       "      <td>0.820602</td>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.815879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_10_percent_data</th>\n",
       "      <td>77.034121</td>\n",
       "      <td>0.776012</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.766538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bf967fe-ed48-4e35-a870-cc6d18c95c35')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4bf967fe-ed48-4e35-a870-cc6d18c95c35 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4bf967fe-ed48-4e35-a870-cc6d18c95c35');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "baseline                 79.265092   0.811139  0.792651  0.786219\n",
       "simple_dense             78.608924   0.790328  0.786089  0.783297\n",
       "lstm                     75.590551   0.756716  0.755906  0.753960\n",
       "gru                      77.559055   0.776327  0.775591  0.774090\n",
       "bidirectional            76.771654   0.767545  0.767717  0.766793\n",
       "conv1d                   78.740157   0.790061  0.787402  0.785228\n",
       "tf_hub_sentence_encoder  81.758530   0.820602  0.817585  0.815879\n",
       "tf_hub_10_percent_data   77.034121   0.776012  0.770341  0.766538"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                  \"simple_dense\": model_1_results,\n",
    "                                  \"lstm\": model_2_results,\n",
    "                                  \"gru\": model_3_results,\n",
    "                                  \"bidirectional\": model_4_results,\n",
    "                                  \"conv1d\": model_5_results,\n",
    "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
    "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "v-s2DSLpmM1F"
   },
   "outputs": [],
   "source": [
    "# Reduce the accuracy to same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "id": "Wp69bR8umD5g",
    "outputId": "cf55f16b-b9ac-4dba-9e29-9a44e27df2d4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avbdkiIuKNNr"
   },
   "source": [
    "Looks like our pretrained USE TensorFlow Hub models have the best performance, even the one with only 10% of the training data seems to outperform the other models. This goes to show the power of transfer learning.\n",
    "\n",
    "How about we drill down and get the F1-score's of each model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "id": "yktdOiufmm3p",
    "outputId": "79b87a0a-2d2a-4621-920d-58f7b1d65491"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "2Ca8TalwGhPf"
   },
   "outputs": [],
   "source": [
    "# # View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
    "# # Upload TensorBoard dev records\n",
    "# !tensorboard dev upload --logdir ./model_logs \\\n",
    "#   --name \"NLP modelling experiments\" \\\n",
    "#   --description \"A series of different NLP modellings experiments with various models\" \\\n",
    "#   --one_shot # exits the uploader when upload has finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIYVXCUJ3FBn"
   },
   "source": [
    "The TensorBoard logs of the different modelling experiments we ran can be viewed here: https://tensorboard.dev/experiment/LkoAakb7QIKBZ0RL97cXbw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "Os7dv00u21jg"
   },
   "outputs": [],
   "source": [
    "# If you need to remove previous experiments, you can do so using the following command\n",
    "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t63u8PCCm-yo",
    "outputId": "37533bb0-0fc4-4ade-e513-27ed85c4d5cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get mean pred probs for 3 models\n",
    "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
    "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
    "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
    "combined_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6abZa7wqlXSI"
   },
   "source": [
    "Wonderful! We've got a combined predictions array of different classes, let's evaluate them against the true labels and add our stacked model's results to our `all_model_results` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieYvhDiev8Et",
    "outputId": "a9779e7d-85d7-4437-954a-745051dfe980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7792442137914578,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7789463852322546}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results from averaging the prediction probabilities\n",
    "ensemble_results = calculate_results(val_labels, combined_preds)\n",
    "ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "132EHlUUpRrP"
   },
   "outputs": [],
   "source": [
    "# Add our combined model's results to the results DataFrame\n",
    "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "Pm2P1zsvpZ3D"
   },
   "outputs": [],
   "source": [
    "# Convert the accuracy to the same scale as the rest of the results\n",
    "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "trmdZ6eEpwHI",
    "outputId": "760e8666-f50e-4183-d8d1-de20867b4c25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-732a719c-3154-4dc3-9244-2e3d783e2015\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.790328</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.783297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.756716</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.753960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.776327</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.774090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.767545</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.766793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.790061</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.785228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.820602</td>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.815879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_10_percent_data</th>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.776012</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.766538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_results</th>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.779244</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.778946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-732a719c-3154-4dc3-9244-2e3d783e2015')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-732a719c-3154-4dc3-9244-2e3d783e2015 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-732a719c-3154-4dc3-9244-2e3d783e2015');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                         accuracy  precision    recall        f1\n",
       "baseline                 0.792651   0.811139  0.792651  0.786219\n",
       "simple_dense             0.786089   0.790328  0.786089  0.783297\n",
       "lstm                     0.755906   0.756716  0.755906  0.753960\n",
       "gru                      0.775591   0.776327  0.775591  0.774090\n",
       "bidirectional            0.767717   0.767545  0.767717  0.766793\n",
       "conv1d                   0.787402   0.790061  0.787402  0.785228\n",
       "tf_hub_sentence_encoder  0.817585   0.820602  0.817585  0.815879\n",
       "tf_hub_10_percent_data   0.770341   0.776012  0.770341  0.766538\n",
       "ensemble_results         0.779528   0.779244  0.779528  0.778946"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZwqwF_swdIA"
   },
   "source": [
    "How did the stacked model go against the other models?\n",
    "\n",
    "> 🔑 **Note:** It seems many of our model's results are similar. This may mean there are some limitations to what can be learned from our data. When many of your modelling experiments return similar results, it's a good idea to revisit your data, we'll do this shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "SlwjGFVyX-_T"
   },
   "outputs": [],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "model_6.save(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp6zvmprm9A3"
   },
   "source": [
    "If you save a model as a `HDF5`, when loading it back in, you need to let [TensorFlow know about any custom objects you've used](https://www.tensorflow.org/tutorials/keras/save_and_load#saving_custom_objects) (e.g. components which aren't built from pure TensorFlow, such as TensorFlow Hub components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "sSINZ0Q-nRb2"
   },
   "outputs": [],
   "source": [
    "# Load model with custom Hub Layer (required with HDF5 format)\n",
    "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", \n",
    "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4BCJ8iXnZ4r",
    "outputId": "dd5e28e0-2c85-453d-be7e-ffd5c3caec07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4298648238182068, 0.817585289478302]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does our loaded model perform?\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02rbT4fwn0It"
   },
   "source": [
    "Calling the `save()` method on our target model and passing it a filepath allows us to save our model in the `SavedModel` format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3eVaNBDoMsv",
    "outputId": "27b38b04-dafc-49f4-e690-c3d7aca05ec5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
     ]
    }
   ],
   "source": [
    "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
    "model_6.save(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-t01S-JoOqK"
   },
   "source": [
    "If you use SavedModel format (default), you can reload your model without specifying custom objects using the [`tensorflow.keras.models.load_model()`](https://www.tensorflow.org/tutorials/keras/save_and_load) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "Dw3zf4fVoU5H"
   },
   "outputs": [],
   "source": [
    "# Load TF Hub Sentence Encoder SavedModel\n",
    "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqiPr6iiofi1",
    "outputId": "cc2e3dbc-86fe-4c2d-c895-77d440faf443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 8ms/step - loss: 0.4299 - accuracy: 0.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4298648238182068, 0.817585289478302]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate loaded SavedModel format\n",
    "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gnHfX--TwMIW",
    "outputId": "57eaf599-c9e2-4541-8fd4-5d1575cc4975"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-941fe3a6-fa8d-43af-a7ed-69e058076d7a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.740579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.740494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-941fe3a6-fa8d-43af-a7ed-69e058076d7a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-941fe3a6-fa8d-43af-a7ed-69e058076d7a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-941fe3a6-fa8d-43af-a7ed-69e058076d7a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text  target  pred  pred_prob\n",
       "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.148141\n",
       "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.740579\n",
       "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988647\n",
       "3  @camilacabello97 Internally and externally scr...       1   0.0   0.224560\n",
       "4  Radiation emergency #preparedness starts with ...       1   1.0   0.740494"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with validation sentences and best performing model predictions\n",
    "val_df = pd.DataFrame({\"text\": val_sentences,\n",
    "                       \"target\": val_labels,\n",
    "                       \"pred\": model_6_preds,\n",
    "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKJ9dTbPrIG4"
   },
   "source": [
    "Oh yeah! Now let's find our model's wrong predictions (where `target != pred`) and sort them by their prediction probability (the `pred_prob` column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "0DwBXQS1wvZx",
    "outputId": "6baf77fd-b2d8-4c44-c86d-d7490ace1f02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-65237c1f-b492-4cba-8952-734fc2d8462d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.839930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.807973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.806746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.782425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>A look at state actions a year after Ferguson'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.759534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65237c1f-b492-4cba-8952-734fc2d8462d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-65237c1f-b492-4cba-8952-734fc2d8462d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-65237c1f-b492-4cba-8952-734fc2d8462d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
       "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
       "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
       "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
       "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
       "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
       "698  åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...       0   1.0   \n",
       "695  A look at state actions a year after Ferguson'...       0   1.0   \n",
       "\n",
       "     pred_prob  \n",
       "31    0.906832  \n",
       "628   0.866348  \n",
       "759   0.859502  \n",
       "393   0.855963  \n",
       "49    0.839930  \n",
       "209   0.815515  \n",
       "251   0.807973  \n",
       "109   0.806746  \n",
       "698   0.782425  \n",
       "695   0.759534  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the wrong predictions and sort by prediction probabilities\n",
    "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
    "most_wrong[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLFYDEsoxRFP",
    "outputId": "75920ca0-eef0-4190-baf2-c21e2164e4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Pred: 1, Prob: 0.9068315625190735\n",
      "Text:\n",
      "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8663479685783386\n",
      "Text:\n",
      "@noah_anyname That's where the concentration camps and mass murder come in. \n",
      " \n",
      "EVERY. FUCKING. TIME.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.859502375125885\n",
      "Text:\n",
      "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8559632897377014\n",
      "Text:\n",
      "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8399295806884766\n",
      "Text:\n",
      "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8155148029327393\n",
      "Text:\n",
      "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8079732060432434\n",
      "Text:\n",
      "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8067457675933838\n",
      "Text:\n",
      "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.7824245095252991\n",
      "Text:\n",
      "åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent Collapse Story: Correction: Tent Collapse story åÈ http://t.co/fDJUYvZMrv @wizkidayo\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.7595335841178894\n",
      "Text:\n",
      "A look at state actions a year after Ferguson's upheaval http://t.co/GZEkQWzijq\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false positives (model predicted 1 when should've been 0)\n",
    "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
    "  _, text, target, pred, prob = row\n",
    "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXCH9J-UspWg"
   },
   "source": [
    "We can view the bottom end of our `most_wrong` DataFrame to inspect false negatives (model predicts 0, not a real diaster Tweet, when it should've predicted 1, real diaster Tweet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EaMchehxwLq",
    "outputId": "4f2effe7-ed64-4f5e-f4e3-b1f0d0464da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, Pred: 0, Prob: 0.06247330829501152\n",
      "Text:\n",
      "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.05949299782514572\n",
      "Text:\n",
      "@BoyInAHorsemask its a panda trapped in a dogs body\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.056083984673023224\n",
      "Text:\n",
      "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.055036477744579315\n",
      "Text:\n",
      "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.054454777389764786\n",
      "Text:\n",
      "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.046157706528902054\n",
      "Text:\n",
      "I get to smoke my shit in peace\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.03960023820400238\n",
      "Text:\n",
      "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.03830057382583618\n",
      "Text:\n",
      "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.03802212327718735\n",
      "Text:\n",
      "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.03466600552201271\n",
      "Text:\n",
      "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the most wrong false negatives (model predicted 0 when should've predict 1)\n",
    "for row in most_wrong[-10:].itertuples():\n",
    "  _, text, target, pred, prob = row\n",
    "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRKQPEAgtpJq"
   },
   "source": [
    "Do you notice anything interesting about the most wrong samples?\n",
    "\n",
    "Are the ground truth labels correct? What do you think would happen if we went back and corrected the labels which aren't?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Q9lgqoDyequ",
    "outputId": "842934bd-3081-40e2-beff-7e8534e61de2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "Pred: 0, Prob: 0.05416637659072876\n",
      "Text:\n",
      "WHAT a day's cricket that was. Has destroyed any plans I had for exercise today.\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Pred: 1, Prob: 0.5330829620361328\n",
      "Text:\n",
      "Any other generation this would've been fatality  http://t.co/zcCtZM9f0o\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Pred: 1, Prob: 0.9940084218978882\n",
      "Text:\n",
      "Arson suspect linked to 30 fires caught in Northern California http://t.co/HkFPyNb4PS\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Pred: 1, Prob: 0.9726524353027344\n",
      "Text:\n",
      "Help support the victims of the Japanese Earthquake and Pacific Tsunami http://t.co/O5GbPBQH http://t.co/MN5wnxf0 #hope4japan #pray4japan\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Pred: 0, Prob: 0.36651405692100525\n",
      "Text:\n",
      "this is from my show last night and im still panicking over the fact i saw sweaty ashton with my own two eyes http://t.co/yyJ76WBC9y\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Pred: 0, Prob: 0.42949625849723816\n",
      "Text:\n",
      "He came to a land which was engulfed in tribal war and turned it into a land of peace i.e. Madinah. #ProphetMuhammad #islam\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Pred: 1, Prob: 0.7450974583625793\n",
      "Text:\n",
      "Jane Kelsey on the FIRE Economy\n",
      "5th Aug 5:30ÛÒ7:30pm\n",
      "Old Govt Buildings Wgton\n",
      "The context &amp; the driver for #TPP and #TRADEinSERVICESAgreement\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Pred: 0, Prob: 0.13024944067001343\n",
      "Text:\n",
      "Detonation fashionable mountaineering electronic watch water-resistant couples leisure tabÛ_ http://t.co/GH48B54riS http://t.co/2PqTm06Lid\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Pred: 1, Prob: 0.8552481532096863\n",
      "Text:\n",
      "@AlbertBrooks Don't like the Ayatollah Khomeini Memorial Nuclear Reactor for the Annihilation of Israel? Racist!\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Pred: 0, Prob: 0.06269928067922592\n",
      "Text:\n",
      "Can you imagine how traumatised Makoto would be if he could see himself in the dub (aka Jersey Shore AU) rn? Well done America\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test dataset\n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
    "  pred = tf.round(pred_prob)\n",
    "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "  print(f\"Text:\\n{test_sample}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcvI5zgJ0Tgp"
   },
   "source": [
    "How do our model's predictions look on the test dataset?\n",
    "\n",
    "It's important to do these kind of visualization checks as often as possible to get a glance of how your model performs on unseen data and subsequently how it might perform on the real test: Tweets from the wild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "qHmXxuPH0aUB"
   },
   "outputs": [],
   "source": [
    "# Turn Tweet into string\n",
    "daniels_tweet = \"Life like an ensemble: take the best choices from others and make your own\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPbZaGznvbEx"
   },
   "source": [
    "Now we'll write a small function to take a model and an example sentence and return a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "KyH9tn9upjld"
   },
   "outputs": [],
   "source": [
    "def predict_on_sentence(model, sentence):\n",
    "  \"\"\"\n",
    "  Uses model to make a prediction on sentence.\n",
    "\n",
    "  Returns the sentence, the predicted label and the prediction probability.\n",
    "  \"\"\"\n",
    "  pred_prob = model.predict([sentence])\n",
    "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
    "  print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
    "  print(f\"Text:\\n{sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvCG4RuUvj6d"
   },
   "source": [
    "Great! Time to test our model out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxONpJV8qmWP",
    "outputId": "9ce8802e-a787-4b09-88b1-84e7e12489a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "Pred: 0.0 (not real disaster) Prob: 0.044768452644348145\n",
      "Text:\n",
      "Life like an ensemble: take the best choices from others and make your own\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction on Tweet from the wild\n",
    "predict_on_sentence(model=model_6, # use the USE model\n",
    "                    sentence=daniels_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYOfNacw08Of"
   },
   "source": [
    "Woohoo! Our model predicted correctly. My Tweet wasn't about a diaster.\n",
    "\n",
    "How about we find a few Tweets about actual diasters?\n",
    "\n",
    "Such as the following two Tweets about the 2020 Beirut explosions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "AqILBsTK2i9R"
   },
   "outputs": [],
   "source": [
    "# Source - https://twitter.com/BeirutCityGuide/status/1290696551376007168\n",
    "beirut_tweet_1 = \"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n",
    "\n",
    "# Source - https://twitter.com/BeirutCityGuide/status/1290773498743476224\n",
    "beirut_tweet_2 = \"#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvlbHDISrVmX",
    "outputId": "eb4dbb3d-0541-4094-f844-034436c7d12f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "Pred: 1.0 (real disaster) Prob: 0.9650391936302185\n",
      "Text:\n",
      "Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\n"
     ]
    }
   ],
   "source": [
    "# Predict on diaster Tweet 1\n",
    "predict_on_sentence(model=model_6, \n",
    "                    sentence=beirut_tweet_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5uKYx11p2zCd",
    "outputId": "54de5279-bdab-4ea3-e24d-1e307f2a56a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Pred: 1.0 (real disaster) Prob: 0.9686568379402161\n",
      "Text:\n",
      "#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\n"
     ]
    }
   ],
   "source": [
    "# Predict on diaster Tweet 2\n",
    "predict_on_sentence(model=model_6, \n",
    "                    sentence=beirut_tweet_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "DnXp8DKOp3J6"
   },
   "outputs": [],
   "source": [
    "# Calculate the time of predictions\n",
    "import time\n",
    "def pred_timer(model, samples):\n",
    "  \"\"\"\n",
    "  Times how long a model takes to make predictions on samples.\n",
    "  \n",
    "  Args:\n",
    "  ----\n",
    "  model = a trained model\n",
    "  sample = a list of samples\n",
    "\n",
    "  Returns:\n",
    "  ----\n",
    "  total_time = total elapsed time for model to make predictions on samples\n",
    "  time_per_pred = time in seconds per single sample\n",
    "  \"\"\"\n",
    "  start_time = time.perf_counter() # get start time\n",
    "  model.predict(samples) # make predictions\n",
    "  end_time = time.perf_counter() # get finish time\n",
    "  total_time = end_time-start_time # calculate how long predictions took to make\n",
    "  time_per_pred = total_time/len(val_sentences) # find prediction time per sample\n",
    "  return total_time, time_per_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxWwS73hze6Z"
   },
   "source": [
    "Looking good!\n",
    "\n",
    "Now let's use our `pred_timer()` function to evaluate the prediction times of our best performing model (`model_6`) and our baseline model (`model_0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMbGMIWd5c9N",
    "outputId": "af030ae6-9ae1-4f15-ca87-8daedba1c2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2243557769999711, 0.0002944301535432692)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TF Hub Sentence Encoder prediction times\n",
    "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n",
    "model_6_total_pred_time, model_6_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4ej2VyT5oQs",
    "outputId": "09eb6fd5-3408-4959-a6d7-6fffdb532f19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.013254724999967493, 1.739465223092847e-05)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Naive Bayes prediction times\n",
    "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
    "baseline_total_pred_time, baseline_time_per_pred"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
